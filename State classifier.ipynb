{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "from environment.system import System\n",
    "from utils import save_pickle, load_pickle\n",
    "\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs': ((151, 133, 215),)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bot': (155,),\n",
       " 'cs': ((190, 162, 224),),\n",
       " 'top': (96,),\n",
       " 'ts1': (0,),\n",
       " 'ts2': (0,)}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = System(brick_ip='ev3dev.local', get_state_mode='dict')\n",
    "env.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if on:\n",
    "    calc_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class StateTrainer:\n",
    "    def __init__(self, env, class_names, samples_per_class, clf, test_size=0.1):\n",
    "        self.class_names = class_names\n",
    "        self.class_map = {\n",
    "            class_name: number for number, class_name in enumerate(self.class_names)\n",
    "        }\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.clf = clf\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.env = env\n",
    "        \n",
    "        self.measurements = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "    def _rgb(self):\n",
    "        return self.env.get_state()['cs'][0]\n",
    "        \n",
    "    def _button1_pressed(self):\n",
    "        return self.env.get_state()['ts1'][0]\n",
    "        \n",
    "    def _gather_measurements(self):\n",
    "        final_measurements = []\n",
    "        for class_n, class_name in enumerate(self.class_names):\n",
    "            class_measurements = []\n",
    "            input(\"Press Enter to continue...\")\n",
    "            print(class_name)\n",
    "            for i in range(self.samples_per_class):\n",
    "                print(\"Collecting samples...\")\n",
    "                \n",
    "#                 print(\"Press button 1 to collect a sample.\")\n",
    "#                 while not self._button1_pressed():\n",
    "#                     pass\n",
    "\n",
    "                time.sleep(0.3)\n",
    "                colors1 = self._rgb()\n",
    "                colors2 = self._rgb()\n",
    "                colors = np.array([colors1, colors2])\n",
    "                class_measurements.append(colors)\n",
    "#                 print(\"Collected sample:\", colors, \"of class\", class_name)\n",
    "            final_measurements.append(class_measurements)\n",
    "        return final_measurements\n",
    "\n",
    "    def get_data_for_training(self):\n",
    "        if self.measurements is None:\n",
    "            self.measurements = self._gather_measurements()\n",
    "        else:\n",
    "            print(\"Already have measurements.\")\n",
    "        \n",
    "        measurements = [np.array(measurement).reshape(-1, 6) for measurement in self.measurements]\n",
    "        X = np.concatenate(measurements)\n",
    "        y_ = [[self.class_map[class_name]]*self.samples_per_class for class_name in self.class_names]\n",
    "        y = np.concatenate(y_)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        return train_test_split(X, y, test_size=self.test_size, stratify=y)\n",
    "    \n",
    "    def train(self)\n",
    "        X_train, X_test, y_train, y_test = self.get_data_for_training()\n",
    "        self.clf.fit(X_train, y_train)\n",
    "        return self.clf.score(X_test, y_test)\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        save_pickle(name, self.clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['off', 'on']\n",
    "samples_per_class = 100\n",
    "st = StateTrainer(env, class_names, samples_per_class=samples_per_class, clf=mlp, test_size=0.1)print(st.train())\n",
    "st.save_model('mlp_on_off.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to continue...\n",
      "off\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Press Enter to continue...\n",
      "on\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(st.train())\n",
    "st.save_model('mlp_on_off.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.20.0 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.20.0 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = load_pickle('mlp_on_off.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    while not st._button1_pressed():\n",
    "        pass\n",
    "    colors = st._rgb()\n",
    "    print(mlp.predict(np.array(colors).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meas_save = st.measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['white', 'black'] {'white': 0, 'black': 1}\n",
      "Press Enter to continue...\n",
      "white\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Press Enter to continue...\n",
      "black\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n",
      "Collecting samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michal\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "class_names = ['white', 'black']\n",
    "samples_per_class = 50\n",
    "st = StateTrainer(env, class_names, samples_per_class=samples_per_class, clf=LogisticRegressionCV(), test_size=0.1)\n",
    "# st.measurements = meas_save\n",
    "print(st.class_names, st.class_map)\n",
    "print(st.train())\n",
    "st.save_model('mlp_white_black.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator LogisticRegressionCV from version 0.20.0 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = load_pickle('mlp_white_black.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.92136257e-01 7.78588830e-03 7.78542412e-05]]\n",
      "[[3.95017874e-30 2.49098904e-02 9.75090110e-01]]\n",
      "[[1.73590613e-14 6.68894507e-01 3.31105493e-01]]\n",
      "[[9.99914401e-01 8.51675171e-05 4.31233506e-07]]\n",
      "[[3.00178007e-12 7.23942901e-01 2.76057099e-01]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    while not st._button1_pressed():\n",
    "        pass\n",
    "    colors = st._rgb()\n",
    "    print(clf.predict_proba(np.array(colors).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
